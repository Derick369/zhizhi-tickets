import requests
from bs4 import BeautifulSoup
import urllib3
import os

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def get_data_and_print():
    url = "https://whly.gd.gov.cn/audit_newspjggg/index.html"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    print("--- æ­£åœ¨æŠ“å–ï¼Œè¯·ç¨å€™ ---")
    session = requests.Session()
    session.trust_env = False
    
    try:
        resp = session.get(url, headers=headers, verify=False, timeout=15)
        resp.encoding = resp.apparent_encoding
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.find_all("a", title=True)

        print("\nğŸ‘‡ è¯·å¤åˆ¶ä¸‹æ–¹è™šçº¿å†…çš„å†…å®¹å¹¶å‘é€ç»™æˆ‘ï¼š")
        print("-" * 30)
        
        count = 0
        with open("titles.txt", "w", encoding="utf-8") as f:
            for a in items:
                title = a['title'].strip()
                if "æ¼”å‡º" in title or "æ¼”å”±ä¼š" in title:
                    print(title) # è¿™ä¸€è¡Œä¼šåœ¨å±å¹•ä¸Šæ˜¾ç¤º
                    f.write(title + "\n")
                    count += 1
        
        print("-" * 30)
        print(f"\næŠ“å–å®Œæˆï¼æ€»è®¡ {count} æ¡ã€‚")
        print(f"å½“å‰æ–‡ä»¶å¤¹è·¯å¾„: {os.getcwd()}") # å‘Šè¯‰ä½ æ–‡ä»¶åˆ°åº•å­˜å“ªäº†

    except Exception as e:
        print(f"âŒ å‡ºé”™äº†: {e}")

if __name__ == "__main__":
    get_data_and_print()